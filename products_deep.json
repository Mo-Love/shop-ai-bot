import requests
from bs4 import BeautifulSoup
import time
import json

BASE_URL = "https://bavovna.team"

def get_product_details(product_url):
    """–ó–∞—Ö–æ–¥–∏—Ç—å –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫—É —Ç–æ–≤–∞—Ä—É —ñ –∑–±–∏—Ä–∞—î –¥–µ—Ç–∞–ª—ñ"""
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        response = requests.get(product_url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        details = {}
        # –ó–∞–∑–≤–∏—á–∞–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ª–µ–∂–∞—Ç—å —É —Ç–∞–±–ª–∏—Ü—è—Ö –∞–±–æ —Å–ø–∏—Å–∫–∞—Ö 
        # –ù–∞ —Å–∞–π—Ç—ñ Bavovna —Ü–µ —á–∞—Å—Ç–æ –±–ª–æ–∫–∏ –∑ –∫–ª–∞—Å–æ–º 'product-properties' –∞–±–æ –ø–æ–¥—ñ–±–Ω—ñ
        properties = soup.find_all('div', class_='property-item') 
        
        for prop in properties:
            name = prop.find('span', class_='property-name').text.strip()
            value = prop.find('span', class_='property-value').text.strip()
            details[name] = value
            
        # –û—Ç—Ä–∏–º—É—î–º–æ –ø–æ–≤–Ω–∏–π –æ–ø–∏—Å
        full_desc = soup.find('div', id='tab-description').text.strip() if soup.find('div', id='tab-description') else ""
        
        return details, full_desc
    except:
        return {}, ""

def deep_scrape():
    catalog_url = f"{BASE_URL}/katalog/"
    headers = {"User-Agent": "Mozilla/5.0"}
    
    response = requests.get(catalog_url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ —Ç–æ–≤–∞—Ä–∏
    product_links = soup.select('.product-card a.product-title') # –£—Ç–æ—á–Ω–µ–Ω–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä
    
    full_catalog = []
    
    print(f"üöÄ –ó–Ω–∞–π–¥–µ–Ω–æ {len(product_links)} —Ç–æ–≤–∞—Ä—ñ–≤. –ü–æ—á–∏–Ω–∞—î–º–æ –≥–ª–∏–±–æ–∫–∏–π –∞–Ω–∞–ª—ñ–∑...")

    for link_tag in product_links[:10]: # –î–ª—è —Ç–µ—Å—Ç—É –±–µ—Ä–µ–º–æ –ø–µ—Ä—à—ñ 10
        url = BASE_URL + link_tag['href']
        name = link_tag.text.strip()
        
        print(f"üì¶ –ü–∞—Ä—Å–∏–º–æ: {name}")
        
        # –í–∏–∫–ª–∏–∫–∞—î–º–æ "–≥–ª–∏–±–æ–∫–∏–π" –ø–∞—Ä—Å–∏–Ω–≥
        specs, description = get_product_details(url)
        
        full_catalog.append({
            "name": name,
            "url": url,
            "characteristics": specs,
            "description": description
        })
        
        # –ü–∞—É–∑–∞, —â–æ–± —Å–∞–π—Ç –Ω–∞—Å –Ω–µ –∑–∞–±–ª–æ–∫—É–≤–∞–≤
        time.sleep(1) 
    
    return full_catalog

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
data = deep_scrape()
with open('products_deep.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=4)

print("‚úÖ –ì–æ—Ç–æ–≤–æ! –î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –≤ products_deep.json")
